train:
  epochs: 200
  lr: 0.0001
  weight_decay: 0.0001
  eta_min: 1.0e-05
  grad_clip: 1.0
  device: cuda:0
  log_interval: 1

loss:
  channel_weights:
  - 1.0
  - 0.5
  - 0.5
  - 0.5
  phys_alpha: 0.5

guard:
  disable: false
  gradcos_interval: 10
  layers:
  - auto
  eps: 1.0e-08

pinn:
  use: true
  k: 24
  samples: 4096
  rho: 1.0
  nu_eff: 0.003
  lambda_mom: 0.001

  warmup: 100
  ramp: 40
  smooth_epochs: 12
  lmax: 0.02
  lmin: 0.002
  schedule: cosine
  mode: down

  # =========================
  # Core-PCGrad 关键：让 PINN “可见”但不劫持
  # =========================
  # 原来的 0.12 会把 effective phys cap 锁死在 sup 的 0.12 倍量级，基本必触发且 scale→1e-6
  # 这里提高预算，让 PINN 能进入训练、raw 能下降，guard 才会“间歇触发”
  max_loss_ratio: 50.0

  # 建议先关闭二次 cap（否则 min(cap_sup, cap_spat) 仍可能把 PINN 压死）
  max_ratio_vs_spatial: 0.0

  # 冷却/恢复参数：避免 pinn_blend 指数归零，体现“冷却→恢复”
  guard_blend_reset: 0.80
  guard_backoff: 0.70
  guard_adapt_min: 0.60
  guard_blend_decay: 0.85
  guard_cooldown: 1
  guard_gamma: 0.97
  cooling_window: 2

  # Core：不启用自适应 λ（保持 core 语义干净）
  adapt: false
  lcont_min_mult: 0.5
  lcont_max_mult: 1.8
  lcont_mult_init: 1.0
  up_rate: 1.05
  down_rate: 0.985
  adapt_after: 121
  adapt_interval: 3

  div_target: 0.1
  div_tol: 0.2
  auto_calib: false
  calib_mult: 0.6
  boost_epochs: 30

teacher:
  use: true
  ema_beta: 0.995
  max_w: 0.2
  decay_eps: 200
  use_best_warm: true
  freeze_after_warm: true
  max_ratio: 0.35
  spatial:
    use: true
    max_deg: 6.0
    weight: 0.05
    max_ratio: 0.2
    gamma: 0.75
    cooling_window: 3
    recover_step: 0.1

p_grad:
  release_epoch: 130
  scale: 0.05

robust:
  subsample_ratio: 1.0
  coord_noise_sigma: 0.0
  field_noise_sigma: 0.0
  occlusion_ratio: 0.0
  occlusion_min: 0.05
  occlusion_max: 0.25
  scale_factor: 1.0
  apply_to_val: false
  apply_to_test: false
  ood_rotation:
    enabled: false
    max_deg: 45.0

curriculum:
  split: 0.8

mixed:
  use: false
  alpha_start: 1.0
  alpha_end: 0.8
  decay_start: 1
  decay_epochs: 200
  schedule: cosine
  wall_sigma: 0.1

adapt:
  enable: false
  start_epoch: 1
  ema_beta: 0.95
  tau: 1.0
  group_velocity: true
  w_min: 0.5
  w_max: 2.0

mo:
  # 维持 solver=pcgrad；配合你的 trainer 逻辑：只在 cooling_active 时进入多目标/PCGrad 分支
  solver: pcgrad
  pcgrad_proj: conflict
  pcgrad_retain_low: true

early:
  patience: 15
  delta: 0.0001

save:
  ok_margin: 0.4
  metric: val_loss

models:
  backbone:
    name: pointnet2pp_ssg
    args:
      out_channels: 4
      p_drop: 0.3
      npoint1: 2048
      npoint2: 512
      npoint3: 128
      k1: 16
      k2: 16
      k3: 16
      c1: 128
      c2: 256
      c3: 512
      groups_gn: 32
      use_pe: false
      use_msg: false
      in_ch0: 0
      p_head_ch:
      - 128
      - 64
      uvw_head_ch:
      - 128
      - 64
      use_graph_refine: true
      refine_k: 16
      refine_layers: 2
      refine_hidden: 128
      refine_residual: true
